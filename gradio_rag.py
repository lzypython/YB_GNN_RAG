import gradio as gr
import torch
import pickle
import numpy as np
from sentence_transformers import SentenceTransformer
import openai
import os
from train_gnn import GCN  # å¯¼å…¥ GCN æ¨¡å‹ç»“æ„

# é…ç½®å’Œåˆå§‹åŒ–
GRAPH_PATH_YW = "graph_yw.pkl"  # è¯ç‰©è¯„ä¼°å›¾
MODEL_PATH_YW = "gnn_model_yw.pt"  # è¯ç‰©è¯„ä¼°æ¨¡å‹
GRAPH_PATH_CX = "graph_cx.pkl"  # é•¿æŠ¤é™©å›¾
MODEL_PATH_CX = "gnn_model_cx.pt"  # é•¿æŠ¤é™©æ¨¡å‹
EMBED_MODEL = "/back-up/gzy/meta-comphrehensive-rag-benchmark-starter-kit/models/sentence-transformers/all-MiniLM-L6-v2/"

client = openai.OpenAI(
    api_key="empty",
    base_url="http://localhost:6081/v1"
)

# å…¨å±€å˜é‡ï¼Œé¿å…é‡å¤åŠ è½½
_G_yw = None
_gnn_model_yw = None
_G_cx = None
_gnn_model_cx = None

def load_resources(task_type):
    """æ ¹æ®ä»»åŠ¡ç±»å‹åŠ è½½å›¾å’Œæ¨¡å‹èµ„æº"""
    global _G_yw, _gnn_model_yw, _G_cx, _gnn_model_cx
    
    if task_type == "æ–°å¢è¯ç‰©åŒ»ä¿å‡†å…¥è¯„ä¼°":
        if _G_yw is None or _gnn_model_yw is None:
            print("æ­£åœ¨åŠ è½½è¯ç‰©è¯„ä¼°å›¾æ•°æ®...")
            with open(GRAPH_PATH_YW, "rb") as f:
                _G_yw = pickle.load(f)
            
            # è·å–èŠ‚ç‚¹ embedding ç»´åº¦
            node_emb_dim = len(_G_yw.nodes[list(_G_yw.nodes())[0]]['embedding'])
            
            # å®šä¹‰æ¨¡å‹ç»“æ„å¹¶åŠ è½½å‚æ•°
            print("æ­£åœ¨åŠ è½½è¯ç‰©è¯„ä¼°GNNæ¨¡å‹...")
            _gnn_model_yw = GCN(in_dim=node_emb_dim, hidden_dim=64)
            _gnn_model_yw.load_state_dict(torch.load(MODEL_PATH_YW))
            print("è¯ç‰©è¯„ä¼°èµ„æºåŠ è½½å®Œæˆï¼")
        
        return _G_yw, _gnn_model_yw
    
    elif task_type == "é•¿æŠ¤é™©å¤±èƒ½é£é™©é¢„æµ‹":
        if _G_cx is None or _gnn_model_cx is None:
            print("æ­£åœ¨åŠ è½½é•¿æŠ¤é™©å›¾æ•°æ®...")
            with open(GRAPH_PATH_CX, "rb") as f:
                _G_cx = pickle.load(f)
            
            # è·å–èŠ‚ç‚¹ embedding ç»´åº¦
            node_emb_dim = len(_G_cx.nodes[list(_G_cx.nodes())[0]]['embedding'])
            
            # å®šä¹‰æ¨¡å‹ç»“æ„å¹¶åŠ è½½å‚æ•°
            print("æ­£åœ¨åŠ è½½é•¿æŠ¤é™©GNNæ¨¡å‹...")
            _gnn_model_cx = GCN(in_dim=node_emb_dim, hidden_dim=64)
            _gnn_model_cx.load_state_dict(torch.load(MODEL_PATH_CX))
            print("é•¿æŠ¤é™©èµ„æºåŠ è½½å®Œæˆï¼")
        
        return _G_cx, _gnn_model_cx
    
    else:
        raise ValueError(f"æœªçŸ¥çš„ä»»åŠ¡ç±»å‹: {task_type}")

from rag_inference import rag_query, rag_query_cx

# å¤„ç†ç”¨æˆ·æŸ¥è¯¢çš„å‡½æ•°
def process_query(query, task_type):
    if not query.strip():
        return "è¯·è¾“å…¥æœ‰æ•ˆçš„é—®é¢˜ã€‚"
    
    try:
        G, gnn_model = load_resources(task_type)
        
        if task_type == "æ–°å¢è¯ç‰©åŒ»ä¿å‡†å…¥è¯„ä¼°":
            answer = rag_query(query, G, gnn_model, topk=5)
        elif task_type == "é•¿æŠ¤é™©å¤±èƒ½é£é™©é¢„æµ‹":
            answer = rag_query_cx(query, G, gnn_model, topk=5)
        else:
            return "è¯·é€‰æ‹©æœ‰æ•ˆçš„ä»»åŠ¡ç±»å‹ã€‚"
            
        return answer
        
    except Exception as e:
        return f"å¤„ç†æŸ¥è¯¢æ—¶å‡ºç°é”™è¯¯ï¼š{str(e)}"

# åˆ›å»ºGradioç•Œé¢
with gr.Blocks(
    title="æ„å»ºå¯ä¿¡å‚åŸŸåŸºç¡€æ¨¡å‹ï¼Œæ¿€å‘åŒ»ä¿å¤§æ•°æ®è¦ç´ çš„åŒ»ç–—å¥åº·æ´»åŠ›",
    theme=gr.themes.Soft(
        primary_hue="blue",
        secondary_hue="gray"
    ),
    css="""
    .gradio-container {
        max-width: 800px;
        margin: auto;
    }
    .title {
        text-align: center;
        font-size: 2.5em;
        font-weight: bold;
        margin-bottom: 20px;
        background: linear-gradient(45deg, #1e88e5, #0d47a1);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
    }
    .description {
        text-align: center;
        font-size: 1.1em;
        margin-bottom: 30px;
        color: #666;
    }
    .input-box {
        border-radius: 10px;
        padding: 20px;
    }
    .output-box {
        border-radius: 10px;
        padding: 20px;
        min-height: 200px;
    }
    .submit-btn {
        background: linear-gradient(45deg, #1e88e5, #0d47a1);
        border: none;
        color: white;
    }
    .submit-btn:hover {
        background: linear-gradient(45deg, #1565c0, #0d47a1);
    }
    .task-selector {
        margin-bottom: 20px;
    }
    """
) as demo:
    
    gr.Markdown(
        """
        <div style="font-size: 1.5em; font-weight: bold;">
            ğŸ¥ æ„å»ºå¯ä¿¡å‚åŸŸåŸºç¡€æ¨¡å‹ï¼Œæ¿€å‘åŒ»ä¿å¤§æ•°æ®è¦ç´ çš„åŒ»ç–—å¥åº·æ´»åŠ›
        </div>
        
        <div class="description" style="font-size: 2.5em;">
            åŸºäºå›¾ç¥ç»ç½‘ç»œå’Œè¯­è¨€æ¨¡å‹çš„æ™ºèƒ½åŒ»ä¿è¯„ä¼°ç³»ç»Ÿï¼Œæä¾›ä¸“ä¸šçš„è¯ç‰©å‡†å…¥è¯„ä¼°å’Œå¤±èƒ½é£é™©é¢„æµ‹
        </div>
        """
    )
    
    with gr.Row():
        with gr.Column(scale=1):
            gr.HTML("""
            <div style="text-align: center;">
                <div style="font-size: 80px; margin-bottom: 20px;">ğŸ¥</div>
            </div>
            """)
    
    # ä»»åŠ¡é€‰æ‹©ä¸‹æ‹‰æ¡†
    with gr.Row():
        task_type = gr.Dropdown(
            choices=["æ–°å¢è¯ç‰©åŒ»ä¿å‡†å…¥è¯„ä¼°", "é•¿æŠ¤é™©å¤±èƒ½é£é™©é¢„æµ‹"],
            label="ğŸ¯ é€‰æ‹©è¯„ä¼°ä»»åŠ¡",
            value="æ–°å¢è¯ç‰©åŒ»ä¿å‡†å…¥è¯„ä¼°",
            info="è¯·é€‰æ‹©è¦è¿›è¡Œçš„è¯„ä¼°ä»»åŠ¡ç±»å‹",
            elem_classes="task-selector"
        )
    
    with gr.Row():
        query_input = gr.Textbox(
            label="ğŸ’¬ è¯·è¾“å…¥è¯„ä¼°å†…å®¹",
            placeholder="è¯·æ ¹æ®é€‰æ‹©çš„ä»»åŠ¡ç±»å‹è¾“å…¥ç›¸åº”å†…å®¹...",
            lines=3,
            max_lines=5,
            container=True,
            elem_classes="input-box"
        )
    
    with gr.Row():
        submit_btn = gr.Button("ğŸš€ å¼€å§‹è¯„ä¼°", variant="primary", size="lg", elem_classes="submit-btn")
        clear_btn = gr.Button("ğŸ—‘ï¸ æ¸…ç©º", variant="secondary", size="lg")
    
    with gr.Row():
        output = gr.Textbox(
            label="ğŸ“‹ ä¸“ä¸šè¯„ä¼°æŠ¥å‘Š",
            lines=8,
            max_lines=15,
            show_copy_button=True,
            container=True,
            elem_classes="output-box"
        )
    
    # çŠ¶æ€æŒ‡ç¤ºå™¨
    status = gr.Textbox(
        label="çŠ¶æ€",
        value="âœ… ç³»ç»Ÿå°±ç»ª",
        interactive=False,
        max_lines=1
    )
    
    # ç¤ºä¾‹é—®é¢˜ - æ ¹æ®ä»»åŠ¡ç±»å‹åŠ¨æ€æ›´æ–°
    drug_examples = [
        ["ç°åœ¨æœ‰ä¸€æ¬¾è¯ï¼Œæ˜¯ä¸€ç§è¡€ç®¡ç´§å¼ ç´ å—ä½“è„‘å•¡è‚½é…¶æŠ‘åˆ¶å‰‚ï¼Œèƒ½å¤Ÿæ˜¾è‘—é™ä½å¿ƒè¡°æ‚£è€…ä½é™¢é£é™©ï¼Œä½†ä»·æ ¼è¾ƒé«˜ï¼Œå®ƒæ˜¯å¦åˆé€‚çº³å…¥åŒ»ä¿è¯ç‰©åå½•ï¼Ÿ"],
        ["ç°åœ¨æœ‰ä¸€æ¬¾è¯ï¼Œæ²»ç–—æ•ˆæœä¸ç°æœ‰è¯ç‰©ç›¸å½“ä½†ä»·æ ¼æ˜¯ç°æœ‰è¯ç‰©çš„ä¸‰å€ï¼Œå®ƒæ˜¯å¦åˆé€‚çº³å…¥åŒ»ä¿è¯ç‰©åå½•ï¼Ÿ"],
        ["ç°åœ¨æœ‰ä¸€ä½82å²ç”·æ€§ï¼Œæ‚£æœ‰é«˜è¡€å‹å’Œç³–å°¿ç—…ï¼Œè„‘æ¢—æ­»åé—ç•™å·¦ä¾§è‚¢ä½“åç˜«ï¼Œè¿‘ä¸¤å¹´å› è·Œå€’éª¨æŠ˜ä½é™¢3æ¬¡ï¼Œè¯¥å‚ä¿äººæ˜¯å¦å±äºé•¿æŠ¤é™©å¤±èƒ½é«˜é£é™©äººç¾¤ï¼Ÿ"],
        ["ç°åœ¨æœ‰ä¸€ä½65å²å¥³æ€§ï¼Œä»…æœ‰è½»åº¦é«˜è¡€å‹ä¸”æ§åˆ¶è‰¯å¥½ï¼Œæ— è·Œå€’å²ï¼Œæ—¥å¸¸ç”Ÿæ´»å®Œå…¨è‡ªç†ï¼Œè¯¥å‚ä¿äººæ˜¯å¦å±äºé•¿æŠ¤é™©å¤±èƒ½é«˜é£é™©äººç¾¤ï¼Ÿ"]
    ]
    
    ltc_examples = [
        ["ç°åœ¨æœ‰ä¸€ä½82å²ç”·æ€§ï¼Œæ‚£æœ‰é«˜è¡€å‹å’Œç³–å°¿ç—…ï¼Œè„‘æ¢—æ­»åé—ç•™å·¦ä¾§è‚¢ä½“åç˜«ï¼Œè¿‘ä¸¤å¹´å› è·Œå€’éª¨æŠ˜ä½é™¢3æ¬¡ï¼Œè¯¥å‚ä¿äººæ˜¯å¦å±äºé•¿æŠ¤é™©å¤±èƒ½é«˜é£é™©äººç¾¤ï¼Ÿ"],
        ["ç°åœ¨æœ‰ä¸€ä½65å²å¥³æ€§ï¼Œä»…æœ‰è½»åº¦é«˜è¡€å‹ä¸”æ§åˆ¶è‰¯å¥½ï¼Œæ— è·Œå€’å²ï¼Œæ—¥å¸¸ç”Ÿæ´»å®Œå…¨è‡ªç†ï¼Œè¯¥å‚ä¿äººæ˜¯å¦å±äºé•¿æŠ¤é™©å¤±èƒ½é«˜é£é™©äººç¾¤ï¼Ÿ"],
        ["ç°åœ¨æœ‰ä¸€ä½78å²ç‹¬å±…å¥³æ€§ï¼Œæ‚£æœ‰éª¨è´¨ç–æ¾å’Œé‡åº¦è†å…³èŠ‚ç‚ï¼Œè¿‡å»ä¸€å¹´æœ‰ä¸¤æ¬¡è·Œå€’è®°å½•ï¼Œå­˜åœ¨è½»åº¦è®¤çŸ¥éšœç¢ï¼Œè¯·è¯„ä¼°å…¶å¤±èƒ½é£é™©"]
    ]
    
    examples = gr.Examples(
        examples=drug_examples,
        inputs=query_input,
        label="ğŸ’¡ ç¤ºä¾‹é—®é¢˜ï¼ˆç‚¹å‡»å³å¯ä½¿ç”¨ï¼‰"
    )
    
    # åº•éƒ¨ä¿¡æ¯
    gr.Markdown(
        """
        ---
        <div style="text-align: center; color: #888; font-size: 0.9em;">
        ğŸ’¡ æç¤ºï¼šæœ¬ç³»ç»Ÿæä¾›çš„ä¿¡æ¯ä»…ä¾›å‚è€ƒï¼Œä¸èƒ½æ›¿ä»£ä¸“ä¸šåŒ»ç–—å†³ç­–ã€‚å¦‚æœ‰åŒ»ç–—é—®é¢˜ï¼Œè¯·å’¨è¯¢ä¸“ä¸šåŒ»ç”Ÿã€‚
        </div>
        """
    )
    
    def update_examples(task_type):
        """æ ¹æ®ä»»åŠ¡ç±»å‹æ›´æ–°ç¤ºä¾‹é—®é¢˜"""
        if task_type == "æ–°å¢è¯ç‰©åŒ»ä¿å‡†å…¥è¯„ä¼°":
            return gr.Examples(examples=drug_examples, inputs=query_input, label="ğŸ’¡ ç¤ºä¾‹é—®é¢˜ï¼ˆç‚¹å‡»å³å¯ä½¿ç”¨ï¼‰")
        else:
            return gr.Examples(examples=ltc_examples, inputs=query_input, label="ğŸ’¡ ç¤ºä¾‹é—®é¢˜ï¼ˆç‚¹å‡»å³å¯ä½¿ç”¨ï¼‰")
    
    def update_placeholder(task_type):
        """æ ¹æ®ä»»åŠ¡ç±»å‹æ›´æ–°è¾“å…¥æ¡†æç¤º"""
        if task_type == "æ–°å¢è¯ç‰©åŒ»ä¿å‡†å…¥è¯„ä¼°":
            return "ä¾‹å¦‚ï¼šç°åœ¨æœ‰ä¸€æ¬¾è¯ï¼Œ[è¯ç‰©æè¿°]ï¼Œå®ƒæ˜¯å¦åˆé€‚çº³å…¥åŒ»ä¿è¯ç‰©åå½•ï¼Ÿ"
        else:
            return "ä¾‹å¦‚ï¼šç°åœ¨æœ‰ä¸€ä½å‚ä¿äººï¼Œ[å‚ä¿äººæè¿°]ï¼Œè¯¥å‚ä¿äººæ˜¯å¦å±äºé•¿æŠ¤é™©å¤±èƒ½é«˜é£é™©äººç¾¤ï¼Ÿ"
    
    # ç»‘å®šäº‹ä»¶
    def submit_query(query, task_type):
        if not query.strip():
            return "è¯·è¾“å…¥æœ‰æ•ˆçš„é—®é¢˜ã€‚", "âŒ è¯·è¾“å…¥é—®é¢˜"
        try:
            status_msg = "â³ æ­£åœ¨å¤„ç†æ‚¨çš„æŸ¥è¯¢..."
            answer = process_query(query, task_type)
            return answer, "âœ… è¯„ä¼°å®Œæˆ"
        except Exception as e:
            return f"å¤„ç†æŸ¥è¯¢æ—¶å‡ºç°é”™è¯¯ï¼š{str(e)}", "âŒ å¤„ç†é”™è¯¯"
    
    submit_btn.click(
        fn=submit_query,
        inputs=[query_input, task_type],
        outputs=[output, status]
    )
    
    clear_btn.click(
        fn=lambda: ("", "", "âœ… ç³»ç»Ÿå°±ç»ª"),
        inputs=[],
        outputs=[query_input, output, status]
    )
    
    # ä»»åŠ¡ç±»å‹å˜åŒ–æ—¶æ›´æ–°ç¤ºä¾‹å’Œæç¤º
    task_type.change(
        fn=update_placeholder,
        inputs=task_type,
        outputs=query_input
    )
    
    # å›è½¦é”®æäº¤
    query_input.submit(
        fn=submit_query,
        inputs=[query_input, task_type],
        outputs=[output, status]
    )

if __name__ == "__main__":
    # å¯åŠ¨ç•Œé¢
    demo.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=False,
        show_error=True
    )